{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heng's Starter code for training the segmentation model on Kaggle.\n",
    "\n",
    "I have not run the kernel with GPU enabled because I do not have much of Kaggle GPU left as of now. So the kernel as expected is giving CUDA error. This is just a simple kernel for training model on Kaggle easily. Made some minor changes to his code and seems like it will run fine here on kaggle. I have not tested the training time. It can exceed the 9 hour limit.\n",
    "\n",
    "The kernel is based on Heng's starter kit version 20190910 you can find it [here](https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/106462#latest-645576) . I have imported 2 utility scripts one for the utility functions with code for plotting and another one is for model. You can fork and edit the utility scripts and add the model classes as you feel like. The model architecture can be changed from this kernel below by changing the Net() class.\n",
    "\n",
    "If you face any problems or errors then feel free to comment them. At last thank you very much Heng and other leaderboard rankers for helping newbies like me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import random \n",
    "from timeit import default_timer as timer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, Sampler\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "from fork_of_heng_s_utility_functions import *\n",
    "from heng_s_models_all import *\n",
    "\n",
    "PI = np.pi\n",
    "IMAGE_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_RGB_STD  = [0.229, 0.224, 0.225]\n",
    "DEFECT_COLOR = [(0,0,0),(0,0,255),(0,255,0),(255,0,0),(0,255,255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DIR = '../input/hengs-split'\n",
    "DATA_DIR = '../input/severstal-steel-defect-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourBalanceClassSampler(Sampler):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        label = (self.dataset.df['Label'].values)\n",
    "        label = label.reshape(-1,4)\n",
    "        label = np.hstack([label.sum(1,keepdims=True)==0,label]).T\n",
    "\n",
    "        self.neg_index  = np.where(label[0])[0]\n",
    "        self.pos1_index = np.where(label[1])[0]\n",
    "        self.pos2_index = np.where(label[2])[0]\n",
    "        self.pos3_index = np.where(label[3])[0]\n",
    "        self.pos4_index = np.where(label[4])[0]\n",
    "\n",
    "        #assume we know neg is majority class\n",
    "        num_neg = len(self.neg_index)\n",
    "        self.length = 4*num_neg\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        neg = self.neg_index.copy()\n",
    "        random.shuffle(neg)\n",
    "        num_neg = len(self.neg_index)\n",
    "\n",
    "        pos1 = np.random.choice(self.pos1_index, num_neg, replace=True)\n",
    "        pos2 = np.random.choice(self.pos2_index, num_neg, replace=True)\n",
    "        pos3 = np.random.choice(self.pos3_index, num_neg, replace=True)\n",
    "        pos4 = np.random.choice(self.pos4_index, num_neg, replace=True)\n",
    "\n",
    "        l = np.stack([neg,pos1,pos2,pos3,pos4]).T\n",
    "        l = l.reshape(-1)\n",
    "        return iter(l)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet\n",
    "def upsize(x,scale_factor=2):\n",
    "    #x = F.interpolate(x, size=e.shape[2:], mode='nearest')\n",
    "    x = F.interpolate(x, scale_factor=scale_factor, mode='nearest')\n",
    "    return x\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class Decode(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Decode, self).__init__()\n",
    "\n",
    "        self.top = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel//2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d( out_channel//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(out_channel//2, out_channel//2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channel//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(out_channel//2, out_channel, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True), #Swish(), #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.top(torch.cat(x, 1))\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def load_pretrain(self, skip, is_print=True):\n",
    "        conversion=copy.copy(CONVERSION)\n",
    "        for i in range(0,len(conversion)-8,4):\n",
    "            conversion[i] = 'block.' + conversion[i][5:]\n",
    "        load_pretrain(self, skip, pretrain_file=PRETRAIN_FILE, conversion=conversion, is_print=is_print)\n",
    "\n",
    "    def __init__(self, num_class=5, drop_connect_rate=0.2):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        e = ResNet18()\n",
    "        self.block = nn.ModuleList([\n",
    "           e.block0,\n",
    "           e.block1,\n",
    "           e.block2,\n",
    "           e.block3,\n",
    "           e.block4\n",
    "        ])\n",
    "        e = None  #dropped\n",
    "\n",
    "        self.decode1 =  Decode(512,     128)\n",
    "        self.decode2 =  Decode(128+256, 128)\n",
    "        self.decode3 =  Decode(128+128, 128)\n",
    "        self.decode4 =  Decode(128+ 64, 128)\n",
    "        self.decode5 =  Decode(128+ 64, 128)\n",
    "        self.logit = nn.Conv2d(128,num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        #----------------------------------\n",
    "        backbone = []\n",
    "        for i in range( len(self.block)):\n",
    "            x = self.block[i](x)\n",
    "            #print(i, x.shape)\n",
    "\n",
    "            if i in [0,1,2,3,4]:\n",
    "                backbone.append(x)\n",
    "\n",
    "        #----------------------------------\n",
    "        x = self.decode1([backbone[-1], ])                   #; print('d1',d1.size())\n",
    "        x = self.decode2([backbone[-2], upsize(x)])          #; print('d2',d2.size())\n",
    "        x = self.decode3([backbone[-3], upsize(x)])          #; print('d3',d3.size())\n",
    "        x = self.decode4([backbone[-4], upsize(x)])          #; print('d4',d4.size())\n",
    "        x = self.decode5([backbone[-5], upsize(x)])          #; print('d5',d5.size())\n",
    "\n",
    "        logit = self.logit(x)\n",
    "        logit = F.interpolate(logit, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class which is used by the infor object in __get_item__\n",
    "class Struct(object):\n",
    "    def __init__(self, is_copy=False, **kwargs):\n",
    "        self.add(is_copy, **kwargs)\n",
    "\n",
    "    def add(self, is_copy=False, **kwargs):\n",
    "        #self.__dict__.update(kwargs)\n",
    "\n",
    "        if is_copy == False:\n",
    "            for key, value in kwargs.items():\n",
    "                setattr(self, key, value)\n",
    "        else:\n",
    "            for key, value in kwargs.items():\n",
    "                try:\n",
    "                    setattr(self, key, copy.deepcopy(value))\n",
    "                    #setattr(self, key, value.copy())\n",
    "                except Exception:\n",
    "                    setattr(self, key, value)\n",
    "\n",
    "    def __str__(self):\n",
    "        text =''\n",
    "        for k,v in self.__dict__.items():\n",
    "            text += '\\t%s : %s\\n'%(k, str(v))\n",
    "        return text\n",
    "\n",
    "# Creating masks\n",
    "def run_length_decode(rle, height=256, width=1600, fill_value=1):\n",
    "    mask = np.zeros((height,width), np.float32)\n",
    "    if rle != '':\n",
    "        mask=mask.reshape(-1)\n",
    "        r = [int(r) for r in rle.split(' ')]\n",
    "        r = np.array(r).reshape(-1, 2)\n",
    "        for start,length in r:\n",
    "            start = start-1  #???? 0 or 1 index ???\n",
    "            mask[start:(start + length)] = fill_value\n",
    "        mask=mask.reshape(width, height).T\n",
    "    return mask\n",
    "\n",
    "# Collations\n",
    "def null_collate(batch):\n",
    "#     pdb.set_trace()\n",
    "    batch_size = len(batch)\n",
    "    input = []\n",
    "    truth_mask  = []\n",
    "    truth_label = []\n",
    "    infor = []\n",
    "    for b in range(batch_size):\n",
    "        input.append(batch[b][0])\n",
    "        #truth_mask.append(batch[b][1])\n",
    "        infor.append(batch[b][2])\n",
    "\n",
    "        mask  = batch[b][1]\n",
    "        label = (mask.reshape(4,-1).sum(1)>0).astype(np.int32)\n",
    "\n",
    "        num_class,H,W = mask.shape\n",
    "        mask = mask.transpose(1,2,0)*[1,2,3,4]\n",
    "        mask = mask.reshape(-1,4)\n",
    "        mask = mask.max(-1).reshape(1,H,W)\n",
    "\n",
    "        truth_mask.append(mask)\n",
    "        truth_label.append(label)\n",
    "\n",
    "    \n",
    "    input = np.stack(input)\n",
    "    input = image_to_input(input, IMAGE_RGB_MEAN,IMAGE_RGB_STD)\n",
    "    input = torch.from_numpy(input).float()\n",
    "\n",
    "    truth_mask = np.stack(truth_mask)\n",
    "    truth_mask = torch.from_numpy(truth_mask).long()\n",
    "\n",
    "    truth_label = np.array(truth_label)\n",
    "    truth_label = torch.from_numpy(truth_label).float()\n",
    "\n",
    "    return input, truth_mask, truth_label, infor\n",
    "\n",
    "# Metric\n",
    "def metric_dice(logit, truth, threshold=0.1, sum_threshold=1):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probability = torch.softmax(logit,1)\n",
    "        probability = one_hot_encode_predict(probability)\n",
    "        truth = one_hot_encode_truth(truth)\n",
    "\n",
    "        batch_size,num_class, H,W = truth.shape\n",
    "        probability = probability.view(batch_size,num_class,-1)\n",
    "        truth = truth.view(batch_size,num_class,-1)\n",
    "        p = (probability>threshold).float()\n",
    "        t = (truth>0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "\n",
    "        d_neg = (p_sum < sum_threshold).float()\n",
    "        d_pos = 2*(p*t).sum(-1)/((p+t).sum(-1)+1e-12)\n",
    "\n",
    "        neg_index = (t_sum==0).float()\n",
    "        pos_index = 1-neg_index\n",
    "\n",
    "        num_neg = neg_index.sum()\n",
    "        num_pos = pos_index.sum(0)\n",
    "        dn = (neg_index*d_neg).sum()/(num_neg+1e-12)\n",
    "        dp = (pos_index*d_pos).sum(0)/(num_pos+1e-12)\n",
    "\n",
    "        #----\n",
    "\n",
    "        dn = dn.item()\n",
    "        dp = list(dp.data.cpu().numpy())\n",
    "        num_neg = num_neg.item()\n",
    "        num_pos = list(num_pos.data.cpu().numpy())\n",
    "\n",
    "    return dn,dp, num_neg,num_pos\n",
    "\n",
    "def metric_hit(logit, truth, threshold=0.5):\n",
    "    batch_size,num_class, H,W = logit.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logit = logit.view(batch_size,num_class,-1)\n",
    "        truth = truth.view(batch_size,-1)\n",
    "\n",
    "        probability = torch.softmax(logit,1)\n",
    "        p = torch.max(probability, 1)[1]\n",
    "        t = truth\n",
    "        correct = (p==t)\n",
    "\n",
    "        index0 = t==0\n",
    "        index1 = t==1\n",
    "        index2 = t==2\n",
    "        index3 = t==3\n",
    "        index4 = t==4\n",
    "\n",
    "        num_neg  = index0.sum().item()\n",
    "        num_pos1 = index1.sum().item()\n",
    "        num_pos2 = index2.sum().item()\n",
    "        num_pos3 = index3.sum().item()\n",
    "        num_pos4 = index4.sum().item()\n",
    "\n",
    "        neg  = correct[index0].sum().item()/(num_neg +1e-12)\n",
    "        pos1 = correct[index1].sum().item()/(num_pos1+1e-12)\n",
    "        pos2 = correct[index2].sum().item()/(num_pos2+1e-12)\n",
    "        pos3 = correct[index3].sum().item()/(num_pos3+1e-12)\n",
    "        pos4 = correct[index4].sum().item()/(num_pos4+1e-12)\n",
    "\n",
    "        num_pos = [num_pos1,num_pos2,num_pos3,num_pos4,]\n",
    "        tn = neg\n",
    "        tp = [pos1,pos2,pos3,pos4,]\n",
    "\n",
    "    return tn,tp, num_neg,num_pos\n",
    "\n",
    "# Loss\n",
    "def criterion(logit, truth, weight=None):\n",
    "    logit = logit.permute(0, 2, 3, 1).contiguous().view(-1, 5)\n",
    "    truth = truth.permute(0, 2, 3, 1).contiguous().view(-1)\n",
    "\n",
    "    if weight is not None: weight = torch.FloatTensor([1]+weight).cuda()\n",
    "    loss = F.cross_entropy(logit, truth, weight=weight, reduction='none')\n",
    "\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "#One-Hot for segmentation\n",
    "def one_hot_encode_truth(truth, num_class=4):\n",
    "    one_hot = truth.repeat(1,num_class,1,1)\n",
    "    arange  = torch.arange(1,num_class+1).view(1,num_class,1,1).to(truth.device)\n",
    "    one_hot = (one_hot == arange).float()\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_encode_predict(predict, num_class=4):\n",
    "    value, index = torch.max(predict, 1, keepdim=True)\n",
    "    value  = value.repeat(1,num_class,1,1)\n",
    "    index  = index.repeat(1,num_class,1,1)\n",
    "    arange = torch.arange(1,num_class+1).view(1,num_class,1,1).to(predict.device)\n",
    "    one_hot = (index == arange).float()\n",
    "    value = value*one_hot\n",
    "    return value\n",
    "\n",
    "# Learning Rate Adjustments\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "       lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "    return lr\n",
    "\n",
    "# Learning Rate Schedule\n",
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb; \n",
    "\n",
    "# def abc():\n",
    "\n",
    "#     next(iter(train_loader))\n",
    "# abc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schduler = NullScheduler(lr=0.001)\n",
    "batch_size = 4 #8\n",
    "iter_accum = 8\n",
    "loss_weight = None#[5,5,2,5] #\n",
    "train_sampler = FourBalanceClassSampler #RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, split, csv, mode, augment=None):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.split   = split\n",
    "        self.csv     = csv\n",
    "        self.mode    = mode\n",
    "        self.augment = augment\n",
    "\n",
    "        self.uid = list(np.concatenate([np.load(SPLIT_DIR + '/%s'%f , allow_pickle=True) for f in split]))\n",
    "        df = pd.concat([pd.read_csv(DATA_DIR + '/%s'%f) for f in csv])\n",
    "        df.fillna('', inplace=True)\n",
    "        df['Class'] = df['ImageId_ClassId'].str[-1].astype(np.int32)\n",
    "        df['Label'] = (df['EncodedPixels']!='').astype(np.int32)\n",
    "        df = df_loc_by_list(df, 'ImageId_ClassId', [ u.split('/')[-1] + '_%d'%c  for u in self.uid for c in [1,2,3,4] ])\n",
    "        self.df = df\n",
    "\n",
    "    def __str__(self):\n",
    "        num1 = (self.df['Class']==1).sum()\n",
    "        num2 = (self.df['Class']==2).sum()\n",
    "        num3 = (self.df['Class']==3).sum()\n",
    "        num4 = (self.df['Class']==4).sum()\n",
    "        pos1 = ((self.df['Class']==1) & (self.df['Label']==1)).sum()\n",
    "        pos2 = ((self.df['Class']==2) & (self.df['Label']==1)).sum()\n",
    "        pos3 = ((self.df['Class']==3) & (self.df['Label']==1)).sum()\n",
    "        pos4 = ((self.df['Class']==4) & (self.df['Label']==1)).sum()\n",
    "\n",
    "        length = len(self)\n",
    "        num = len(self)*4\n",
    "        pos = (self.df['Label']==1).sum()\n",
    "        neg = num-pos\n",
    "\n",
    "        #---\n",
    "\n",
    "        string  = ''\n",
    "        string += '\\tmode    = %s\\n'%self.mode\n",
    "        string += '\\tsplit   = %s\\n'%self.split\n",
    "        string += '\\tcsv     = %s\\n'%str(self.csv)\n",
    "        string += '\\t\\tlen   = %5d\\n'%len(self)\n",
    "        if self.mode == 'train':\n",
    "            string += '\\t\\tnum   = %5d\\n'%num\n",
    "            string += '\\t\\tneg   = %5d  %0.3f\\n'%(neg,neg/num)\n",
    "            string += '\\t\\tpos   = %5d  %0.3f\\n'%(pos,pos/num)\n",
    "            string += '\\t\\tpos1  = %5d  %0.3f  %0.3f\\n'%(pos1,pos1/length,pos1/pos)\n",
    "            string += '\\t\\tpos2  = %5d  %0.3f  %0.3f\\n'%(pos2,pos2/length,pos2/pos)\n",
    "            string += '\\t\\tpos3  = %5d  %0.3f  %0.3f\\n'%(pos3,pos3/length,pos3/pos)\n",
    "            string += '\\t\\tpos4  = %5d  %0.3f  %0.3f\\n'%(pos4,pos4/length,pos4/pos)\n",
    "        return string\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.uid)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        folder, image_id = self.uid[index].split('/')\n",
    "\n",
    "        rle = [\n",
    "            self.df.loc[self.df['ImageId_ClassId']==image_id + '_1','EncodedPixels'].values[0],\n",
    "            self.df.loc[self.df['ImageId_ClassId']==image_id + '_2','EncodedPixels'].values[0],\n",
    "            self.df.loc[self.df['ImageId_ClassId']==image_id + '_3','EncodedPixels'].values[0],\n",
    "            self.df.loc[self.df['ImageId_ClassId']==image_id + '_4','EncodedPixels'].values[0],\n",
    "        ]\n",
    "        image = cv2.imread(DATA_DIR + '/%s/%s'%(folder,image_id), cv2.IMREAD_COLOR)\n",
    "        mask  = np.array([run_length_decode(r, height=256, width=1600, fill_value=1) for r in rle])\n",
    "\n",
    "        infor = Struct(\n",
    "            index    = index,\n",
    "            folder   = folder,\n",
    "            image_id = image_id,\n",
    "        )\n",
    "\n",
    "        if self.augment is None:\n",
    "            return image, mask, infor\n",
    "        else:\n",
    "            return self.augment(image, mask, infor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_valid(net, valid_loader, displays=None):\n",
    "    valid_num  = np.zeros(11, np.float32)\n",
    "    valid_loss = np.zeros(11, np.float32)\n",
    "    \n",
    "    for t, (input, truth_mask, truth_label, infor) in enumerate(valid_loader):\n",
    "\n",
    "        #if b==5: break\n",
    "        net.eval()\n",
    "        input = input.cuda()\n",
    "        truth_mask  = truth_mask.cuda()\n",
    "        truth_label = truth_label.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logit = net(input) #data_parallel(net, input)\n",
    "            loss  = criterion(logit, truth_mask)\n",
    "            tn,tp, num_neg,num_pos = metric_hit(logit, truth_mask)\n",
    "            dn,dp, num_neg,num_pos = metric_dice(logit, truth_mask, threshold=0.5, sum_threshold=100)\n",
    "            \n",
    "            #zz=0\n",
    "        #---\n",
    "        batch_size = len(infor)\n",
    "        l = np.array([ loss.item(), tn,*tp, dn,*dp ])\n",
    "        n = np.array([ batch_size, num_neg,*num_pos, num_neg,*num_pos ])\n",
    "        valid_loss += l*n\n",
    "        valid_num  += n\n",
    "\n",
    "        #debug-----------------------------\n",
    "        if displays is not None:\n",
    "            probability = torch.sigmoid(logit)\n",
    "            image = input_to_image(input, IMAGE_RGB_MEAN,IMAGE_RGB_STD)\n",
    "\n",
    "            probability = one_hot_encode_predict(probability)\n",
    "            truth_mask  = one_hot_encode_truth(truth_mask)\n",
    "            \n",
    "            probability_mask = probability.data.cpu().numpy()\n",
    "            truth_label = truth_label.data.cpu().numpy()\n",
    "            truth_mask  = truth_mask.data.cpu().numpy()\n",
    "\n",
    "            for b in range(0, batch_size, 4):\n",
    "                image_id = infor[b].image_id[:-4]\n",
    "                result = draw_predict_result_label(image[b], truth_mask[b], truth_label[b], probability_mask[b], stack='vertical')\n",
    "                draw_shadow_text(result,'%05d    %s.jpg'%(valid_num[0]-batch_size+b, image_id),(5,24),1,[255,255,255],2)\n",
    "                image_show('result',result,resize=1)\n",
    "#                 cv2.imwrite(out_dir +'/valid/%s.png'%(image_id), result)\n",
    "#                 cv2.waitKey(1)\n",
    "                pass\n",
    "        #debug-----------------------------\n",
    "\n",
    "        #print(valid_loss)\n",
    "        print('\\r %8d /%8d'%(valid_num[0], len(valid_loader.dataset)),end='',flush=True)\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    assert(valid_num[0] == len(valid_loader.dataset))\n",
    "    valid_loss = valid_loss/valid_num\n",
    "\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    batch_size = 4\n",
    "\n",
    "    initial_checkpoint = \\\n",
    "    '/root/share/project/kaggle/2019/steel/result1/resnet34-cls-full-foldb0-0/checkpoint/00007500_model.pth'\n",
    "    \n",
    "    train_dataset = SteelDataset(\n",
    "        mode    = 'train',\n",
    "        csv     = ['train.csv',],\n",
    "        split   = ['train_b1_11568.npy',],\n",
    "        augment = train_augment,\n",
    "    )\n",
    "    train_loader  = DataLoader(\n",
    "        train_dataset,\n",
    "        #sampler     = BalanceClassSampler(train_dataset, 3*len(train_dataset)),\n",
    "        #sampler    = SequentialSampler(train_dataset),\n",
    "        sampler    = train_sampler(train_dataset),\n",
    "        batch_size  = batch_size,\n",
    "        drop_last   = True,\n",
    "        num_workers = 2,\n",
    "        pin_memory  = True,\n",
    "        collate_fn  = null_collate\n",
    "    )\n",
    "\n",
    "    valid_dataset = SteelDataset(\n",
    "        mode    = 'train',\n",
    "        csv     = ['train.csv',],\n",
    "        split   = ['valid_b1_1000.npy',],\n",
    "        augment = valid_augment,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        sampler    = SequentialSampler(valid_dataset),\n",
    "        #sampler     = RandomSampler(valid_dataset),\n",
    "        batch_size  = 4,\n",
    "        drop_last   = False,\n",
    "        num_workers = 2,\n",
    "        pin_memory  = True,\n",
    "        collate_fn  = null_collate\n",
    "    )\n",
    "    \n",
    "    assert(len(train_dataset)>=batch_size)\n",
    "    \n",
    "    net = Net().cuda()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=schduler(0), momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    num_iters   = 3000*1000\n",
    "    iter_smooth = 50\n",
    "    iter_log    = 500\n",
    "    iter_valid  = 1500\n",
    "    iter_save   = [0, num_iters-1]\\\n",
    "                   + list(range(0, num_iters, 1500))#1*1000\n",
    "\n",
    "    start_iter = 0\n",
    "    start_epoch= 0\n",
    "    rate       = 0\n",
    "    if initial_checkpoint is not None:\n",
    "        initial_optimizer = initial_checkpoint.replace('_model.pth','_optimizer.pth')\n",
    "        if os.path.exists(initial_optimizer):\n",
    "            checkpoint  = torch.load(initial_optimizer)\n",
    "            start_iter  = checkpoint['iter' ]\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        pass\n",
    "    \n",
    "    train_loss = np.zeros(20,np.float32)\n",
    "    valid_loss = np.zeros(20,np.float32)\n",
    "    batch_loss = np.zeros(20,np.float32)\n",
    "    iter = 0\n",
    "    i    = 0\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    while  iter<num_iters:\n",
    "        sum_train_loss = np.zeros(20,np.float32)\n",
    "        sum = np.zeros(20,np.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for t, (input, truth_mask, truth_label, infor) in enumerate(train_loader):\n",
    "            batch_size = len(infor)\n",
    "            iter  = i + start_iter\n",
    "            epoch = (iter-start_iter)*batch_size/len(train_dataset) + start_epoch\n",
    "            \n",
    "            # Weather to display images or not! While in validation loss\n",
    "            displays = None\n",
    "            #if 0:\n",
    "            if (iter % iter_valid==0):\n",
    "                valid_loss = do_valid(net, valid_loader, displays) # omitted outdir variable\n",
    "                #pass\n",
    "\n",
    "            if (iter % iter_log==0):\n",
    "                print('\\r',end='',flush=True)\n",
    "                asterisk = '*' if iter in iter_save else ' '\n",
    "                print('%0.5f  %5.1f%s %5.1f |  %5.3f   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]  |  %5.3f   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]  | %s' % (\\\n",
    "                         rate, iter/1000, asterisk, epoch,\n",
    "                         *valid_loss[:11],\n",
    "                         *train_loss[:6],\n",
    "                         time_to_str((timer() - start),'min'))\n",
    "                )\n",
    "                print('\\n')\n",
    "                \n",
    "            #if 0:\n",
    "            if iter in iter_save:\n",
    "                torch.save(net.state_dict(),'../working/%08d_model.pth'%(iter))\n",
    "                torch.save({\n",
    "                    #'optimizer': optimizer.state_dict(),\n",
    "                    'iter'     : iter,\n",
    "                    'epoch'    : epoch,\n",
    "                }, '../working/%08d_optimizer.pth'%(iter))\n",
    "                pass\n",
    "\n",
    "            # learning rate schduler -------------\n",
    "            lr = schduler(iter)\n",
    "            if lr<0 : break\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "            rate = get_learning_rate(optimizer)\n",
    "            \n",
    "            net.train()\n",
    "            input = input.cuda()\n",
    "            truth_label = truth_label.cuda()\n",
    "            truth_mask  = truth_mask.cuda()\n",
    "\n",
    "            logit =  net(input) #data_parallel(net,input)  \n",
    "            loss = criterion(logit, truth_mask, loss_weight)\n",
    "            tn,tp, num_neg,num_pos = metric_hit(logit, truth_mask)\n",
    "            \n",
    "            (loss/iter_accum).backward()\n",
    "            if (iter % iter_accum)==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # print statistics  ------------\n",
    "            l = np.array([ loss.item(), tn,*tp ])\n",
    "            n = np.array([ batch_size, num_neg,*num_pos ])\n",
    "\n",
    "            batch_loss[:6] = l\n",
    "            sum_train_loss[:6] += l*n\n",
    "            sum[:6] += n\n",
    "            if iter%iter_smooth == 0:\n",
    "                train_loss = sum_train_loss/(sum+1e-12)\n",
    "                sum_train_loss[...] = 0\n",
    "                sum[...]            = 0\n",
    "\n",
    "\n",
    "            print('\\r',end='',flush=True)\n",
    "            asterisk = ' '\n",
    "            print('%0.5f  %5.1f%s %5.1f |  %5.3f   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]  |  %5.3f   %4.2f [%4.2f,%4.2f,%4.2f,%4.2f]  | %s' % (\\\n",
    "                     rate, iter/1000, asterisk, epoch,\n",
    "                     *valid_loss[:11],\n",
    "                     *train_loss[:6],\n",
    "                     time_to_str((timer() - start),'min'))\n",
    "            )\n",
    "            print('\\n')\n",
    "            i=i+1\n",
    "            \n",
    "            # debug-----------------------------\n",
    "            if 1:\n",
    "                for di in range(3):\n",
    "                    if (iter+di)%1000==0:\n",
    "\n",
    "                        probability = torch.softmax(logit,1)\n",
    "                        image = input_to_image(input, IMAGE_RGB_MEAN,IMAGE_RGB_STD)\n",
    "                        \n",
    "                        probability = one_hot_encode_predict(probability)\n",
    "                        truth_mask  = one_hot_encode_truth(truth_mask)\n",
    "                        \n",
    "                        probability_mask = probability.data.cpu().numpy()\n",
    "                        truth_label = truth_label.data.cpu().numpy()\n",
    "                        truth_mask  = truth_mask.data.cpu().numpy()\n",
    "\n",
    "\n",
    "                        for b in range(batch_size):\n",
    "                    \n",
    "                            result = draw_predict_result_label(image[b], truth_mask[b], truth_label[b], probability_mask[b], stack='vertical')\n",
    "\n",
    "                            image_show('result',result,resize=1)\n",
    "#                             cv2.imwrite('../working/%05d.png'%(di*100+b), result)\n",
    "#                             cv2.waitKey(1)\n",
    "                            pass\n",
    "        pass  #-- end of one data loader --\n",
    "    pass #-- end of all iterations --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      |-------------------------------- VALID-----------------------------|---------- TRAIN/BATCH ------------------------------\n",
      "\n",
      "rate     iter   epoch |  loss    hit_neg,pos1,2,3,4           dice_neg,pos1,2,3,4         |  loss    hit_neg,pos1,2,3,4          | time         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f20ae86a9c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------------------------------------------------------------------------------------------------------------------------------\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0;31m#0.00000    0.0*   0.0 |  0.690   0.50 [0.00,1.00,0.00,1.00]   0.44 [0.00,0.02,0.00,0.15]  |  0.000   0.00 [0.00,0.00,0.00,0.00]  |  0 hr 00 min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f9a6c66bffc3>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         raise RuntimeError(\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print('                      |-------------------------------- VALID-----------------------------|---------- TRAIN/BATCH ------------------------------\\n')\n",
    "print('rate     iter   epoch |  loss    hit_neg,pos1,2,3,4           dice_neg,pos1,2,3,4         |  loss    hit_neg,pos1,2,3,4          | time         \\n')\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------------\\n')\n",
    "          #0.00000    0.0*   0.0 |  0.690   0.50 [0.00,1.00,0.00,1.00]   0.44 [0.00,0.02,0.00,0.15]  |  0.000   0.00 [0.00,0.00,0.00,0.00]  |  0 hr 00 min\n",
    "run_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
