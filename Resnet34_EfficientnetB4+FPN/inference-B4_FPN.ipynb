{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null\n",
    "#package_path = '../input/unet-model'\n",
    "package_path = '../input/fpnscript' # add FPN script dataset\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Get necessary Imports\n",
    "import pdb\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (Normalize, Compose)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Codes from Heng's baseline\n",
    "# This code is for classifcation model\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "\n",
    "IMAGE_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_RGB_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "###############################################################################\n",
    "class ConvBn2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, stride=1):\n",
    "        super(ConvBn2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding, stride=stride, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channel, eps=1e-5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "#############  resnext50 pyramid feature net #######################################\n",
    "# https://github.com/Hsuxu/ResNeXt/blob/master/models.py\n",
    "# https://github.com/D-X-Y/ResNeXt-DenseNet/blob/master/models/resnext.py\n",
    "# https://github.com/miraclewkf/ResNeXt-PyTorch/blob/master/resnext.py\n",
    "\n",
    "# bottleneck type C\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channel, channel, out_channel, stride=1, is_shortcut=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.is_shortcut = is_shortcut\n",
    "\n",
    "        self.conv_bn1 = ConvBn2d(in_channel,    channel, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv_bn2 = ConvBn2d(   channel,out_channel, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        if is_shortcut:\n",
    "            self.shortcut = ConvBn2d(in_channel, out_channel, kernel_size=1, padding=0, stride=stride)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.conv_bn1(x),inplace=True)\n",
    "        z = self.conv_bn2(z)\n",
    "\n",
    "        if self.is_shortcut:\n",
    "            x = self.shortcut(x)\n",
    "\n",
    "        z += x\n",
    "        z = F.relu(z,inplace=True)\n",
    "        return z\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class=1000 ):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "\n",
    "        self.block0  = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3, stride=2, bias=False),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.block1  = nn.Sequential(\n",
    "             nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
    "             BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,),\n",
    "          * [BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.block2  = nn.Sequential(\n",
    "             BasicBlock( 64,128,128, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(128,128,128, stride=1, is_shortcut=False,) for i in range(1,4)],\n",
    "        )\n",
    "        self.block3  = nn.Sequential(\n",
    "             BasicBlock(128,256,256, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(256,256,256, stride=1, is_shortcut=False,) for i in range(1,6)],\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "             BasicBlock(256,512,512, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(512,512,512, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.logit = nn.Linear(512,num_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        logit = self.logit(x)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet34_classification(nn.Module):\n",
    "    def __init__(self,num_class=4):\n",
    "        super(Resnet34_classification, self).__init__()\n",
    "        e = ResNet34()\n",
    "        self.block = nn.ModuleList([\n",
    "            e.block0,\n",
    "            e.block1,\n",
    "            e.block2,\n",
    "            e.block3,\n",
    "            e.block4,\n",
    "        ])\n",
    "        e = None  #dropped\n",
    "        self.feature = nn.Conv2d(512,32, kernel_size=1) #dummy conv for dim reduction\n",
    "        self.logit = nn.Conv2d(32,num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        for i in range( len(self.block)):\n",
    "            x = self.block[i](x)\n",
    "            #print(i, x.shape)\n",
    "\n",
    "        x = F.dropout(x,0.5,training=self.training)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.feature(x)\n",
    "        logit = self.logit(x)\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification = Resnet34_classification()\n",
    "model_classification.load_state_dict(torch.load('../input/clsification/00007500_model.pth', map_location=lambda storage, loc: storage), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std):\n",
    "        self.root = root\n",
    "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Normalize(mean=mean, std=std, p=1),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n",
    "test_data_folder = \"../input/severstal-steel-defect-detection/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 1\n",
    "\n",
    "# mean and std\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sample_submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions for setting up inference\n",
    "\n",
    "def sharpen(p,t=0.5):\n",
    "        if t!=0:\n",
    "            return p**t\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "def get_classification_preds(net,test_loader):\n",
    "    test_probability_label = []\n",
    "    test_id   = []\n",
    "    \n",
    "    net = net.cuda()\n",
    "    for t, (fnames, images) in enumerate(tqdm(test_loader)):\n",
    "        batch_size,C,H,W = images.shape\n",
    "        images = images.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "\n",
    "            num_augment = 0\n",
    "            if 1: #  null\n",
    "                logit =  net(images)\n",
    "                probability = torch.sigmoid(logit)\n",
    "\n",
    "                probability_label = sharpen(probability,0)\n",
    "                num_augment+=1\n",
    "\n",
    "            if 'flip_lr' in augment:\n",
    "                logit = net(torch.flip(images,dims=[3]))\n",
    "                probability  = torch.sigmoid(logit)\n",
    "\n",
    "                probability_label += sharpen(probability)\n",
    "                num_augment+=1\n",
    "\n",
    "            if 'flip_ud' in augment:\n",
    "                logit = net(torch.flip(images,dims=[2]))\n",
    "                probability = torch.sigmoid(logit)\n",
    "\n",
    "                probability_label += sharpen(probability)\n",
    "                num_augment+=1\n",
    "\n",
    "            probability_label = probability_label/num_augment\n",
    "\n",
    "        probability_label = probability_label.data.cpu().numpy()\n",
    "        \n",
    "        test_probability_label.append(probability_label)\n",
    "        test_id.extend([i for i in fnames])\n",
    "\n",
    "    \n",
    "    test_probability_label = np.concatenate(test_probability_label)\n",
    "    return test_probability_label, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold for classification\n",
    "threshold_label = [0.50,0.50,0.50,0.50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = ['null'] #['null', 'flip_lr','flip_ud'] #['null, 'flip_lr','flip_ud','5crop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1801/1801 [00:48<00:00, 37.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get prediction for classification model\n",
    "probability_label, image_id = get_classification_preds(model_classification, testset)\n",
    "predict_label = probability_label>np.array(threshold_label).reshape(1,4,1,1)\n",
    "\n",
    "image_id_class_id = []\n",
    "encoded_pixel = []\n",
    "\n",
    "for b in range(len(image_id)):\n",
    "    for c in range(4):\n",
    "        image_id_class_id.append(image_id[b]+'_%d'%(c+1))\n",
    "        if predict_label[b,c]==0:\n",
    "            rle=''\n",
    "        else:\n",
    "            rle ='1 1'\n",
    "        encoded_pixel.append(rle)\n",
    "\n",
    "df_classification = pd.DataFrame(zip(image_id_class_id, encoded_pixel), columns=['ImageId_ClassId', 'EncodedPixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels\n",
       "0  004f40c73.jpg_1              \n",
       "1  004f40c73.jpg_2              \n",
       "2  004f40c73.jpg_3              \n",
       "3  004f40c73.jpg_4              \n",
       "4  006f39c41.jpg_1              "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FPN.py']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/fpnscript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ../input/effnet-dependency -e . > /dev/null\n",
    "!pip install ../input/efficientnetpytorch/efficientnet_pytorch-0.4.0/ > /dev/null\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FPN import FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get segmentation model and load weights\n",
    "\n",
    "# Initialize mode and load trained weights\n",
    "ckpt_path = '../input/fpnb4-model-48000iter-166epo/00048000_modelFPN.pth'\n",
    "device = torch.device(\"cuda\")\n",
    "model_segmentation = FPN('efficientnet-b4', encoder_weights=None, classes=5)\n",
    "model_segmentation.to(device)\n",
    "model_segmentation.eval()\n",
    "model_segmentation.load_state_dict(torch.load(ckpt_path, map_location=lambda storage, loc: storage), strict=False)\n",
    "# state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "# state_dict = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "# model_segmentation.load_state_dict(state_dict,strict=False)\n",
    "# model_segmentation.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_segmentation] # add other models for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds and min_size for segmentation predictions\n",
    "# play with them and see how LB changes\n",
    "threshold_pixel = [0.4,0.4,0.5,0.65,] \n",
    "min_size = [400,600,800,1800]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test time augmentation  -----------------------\n",
    "def null_augment   (input): return input\n",
    "def flip_lr_augment(input): return torch.flip(input, dims=[2])\n",
    "def flip_ud_augment(input): return torch.flip(input, dims=[3])\n",
    "\n",
    "def null_inverse_augment   (logit): return logit\n",
    "def flip_lr_inverse_augment(logit): return torch.flip(logit, dims=[2])\n",
    "def flip_ud_inverse_augment(logit): return torch.flip(logit, dims=[3])\n",
    "\n",
    "augment = (\n",
    "        (null_augment,   null_inverse_augment   ),\n",
    "        (flip_lr_augment,flip_lr_inverse_augment),\n",
    "        (flip_ud_augment,flip_ud_inverse_augment),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: ImageId_ClassId, dtype: object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.EncodedPixels.values != '1 1']['ImageId_ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_predict(predict, num_class=4):\n",
    "    value, index = torch.max(predict, 1, keepdim=True)\n",
    "\n",
    "    value  = value.repeat(1,num_class,1,1)\n",
    "    index  = index.repeat(1,num_class,1,1)\n",
    "    arange = torch.arange(1,num_class+1).view(1,num_class,1,1).to(predict.device)\n",
    "\n",
    "    one_hot = (index == arange).float()\n",
    "    value = value*one_hot\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1801/1801 [04:42<00:00,  6.37it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    fnames, images = batch\n",
    "    #print('images', images.shape)\n",
    "    images = images.cuda()\n",
    "    batch_preds = 0\n",
    "    probabilities = []\n",
    "    for model in models:\n",
    "        model = model.cuda()\n",
    "        for k, (a, inv_a) in enumerate(augment):\n",
    "                logit = model(a(images))\n",
    "                p = inv_a(torch.sigmoid(logit))\n",
    "\n",
    "                if k ==0:\n",
    "                    probability  = p**0.5\n",
    "                else:\n",
    "                    probability += p**0.5\n",
    "        probability = probability/len(augment)\n",
    "        probabilities.append(probability)\n",
    "        \n",
    "        batch_preds+=probability\n",
    "    batch_preds = one_hot_encode_predict(batch_preds)\n",
    "    batch_preds = batch_preds.data.cpu().numpy()\n",
    "    #print(batch_preds.shape)\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            #print(cls)\n",
    "            pred, num = post_process(pred, threshold_pixel[cls], min_size[cls])\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "\n",
    "df_segmentation = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_segmentation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tnum_image =  1801(1801)\n",
      "\t\tnum  =  7204(7204)\n",
      "\t\tneg  =  6617(6172)  0.919\n",
      "\t\tpos  =   587(1032)  0.081\n",
      "\t\tpos1 =   103( 128)  0.057  0.175\n",
      "\t\tpos2 =    17(  43)  0.009  0.029\n",
      "\t\tpos3 =   339( 741)  0.188  0.578\n",
      "\t\tpos4 =   128( 120)  0.071  0.218\n"
     ]
    }
   ],
   "source": [
    "# stats for predictions from segmentation model\n",
    "if 1:\n",
    "        df['Class'] = df['ImageId_ClassId'].str[-1].astype(np.int32)\n",
    "        df['Label'] = (df['EncodedPixels']!='').astype(np.int32)\n",
    "        pos1 = ((df['Class']==1) & (df['Label']==1)).sum()\n",
    "        pos2 = ((df['Class']==2) & (df['Label']==1)).sum()\n",
    "        pos3 = ((df['Class']==3) & (df['Label']==1)).sum()\n",
    "        pos4 = ((df['Class']==4) & (df['Label']==1)).sum()\n",
    "\n",
    "        num_image = len(df)//4\n",
    "        num = len(df)\n",
    "        pos = (df['Label']==1).sum()\n",
    "        neg = num-pos\n",
    "\n",
    "        print('')\n",
    "        print('\\t\\tnum_image = %5d(1801)'%num_image)\n",
    "        print('\\t\\tnum  = %5d(7204)'%num)\n",
    "        print('\\t\\tneg  = %5d(6172)  %0.3f'%(neg,neg/num))\n",
    "        print('\\t\\tpos  = %5d(1032)  %0.3f'%(pos,pos/num))\n",
    "        print('\\t\\tpos1 = %5d( 128)  %0.3f  %0.3f'%(pos1,pos1/num_image,pos1/pos))\n",
    "        print('\\t\\tpos2 = %5d(  43)  %0.3f  %0.3f'%(pos2,pos2/num_image,pos2/pos))\n",
    "        print('\\t\\tpos3 = %5d( 741)  %0.3f  %0.3f'%(pos3,pos3/num_image,pos3/pos))\n",
    "        print('\\t\\tpos4 = %5d( 120)  %0.3f  %0.3f'%(pos4,pos4/num_image,pos4/pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask = df_segmentation.copy()\n",
    "df_label = df_classification.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "# do filtering using predictions from classification and segmentation models\n",
    "assert(np.all(df_mask['ImageId_ClassId'].values == df_label['ImageId_ClassId'].values))\n",
    "print((df_mask.loc[df_label['EncodedPixels']=='','EncodedPixels'] != '').sum() ) #202\n",
    "df_mask.loc[df_label['EncodedPixels']=='','EncodedPixels']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tnum_image =  1801(1801)\n",
      "\t\tnum  =  7204(7204)\n",
      "\t\tneg  =  6807(6172)  0.945\n",
      "\t\tpos  =   397(1032)  0.055\n",
      "\t\tpos1 =    35( 128)  0.019  0.088\n",
      "\t\tpos2 =     5(  43)  0.003  0.013\n",
      "\t\tpos3 =   250( 741)  0.139  0.630\n",
      "\t\tpos4 =   107( 120)  0.059  0.270\n"
     ]
    }
   ],
   "source": [
    "# stats for final submission\n",
    "if 1:\n",
    "        df_mask['Class'] = df_mask['ImageId_ClassId'].str[-1].astype(np.int32)\n",
    "        df_mask['Label'] = (df_mask['EncodedPixels']!='').astype(np.int32)\n",
    "        pos1 = ((df_mask['Class']==1) & (df_mask['Label']==1)).sum()\n",
    "        pos2 = ((df_mask['Class']==2) & (df_mask['Label']==1)).sum()\n",
    "        pos3 = ((df_mask['Class']==3) & (df_mask['Label']==1)).sum()\n",
    "        pos4 = ((df_mask['Class']==4) & (df_mask['Label']==1)).sum()\n",
    "\n",
    "        num_image = len(df_mask)//4\n",
    "        num = len(df_mask)\n",
    "        pos = (df_mask['Label']==1).sum()\n",
    "        neg = num-pos\n",
    "\n",
    "        print('')\n",
    "        print('\\t\\tnum_image = %5d(1801)'%num_image)\n",
    "        print('\\t\\tnum  = %5d(7204)'%num)\n",
    "        print('\\t\\tneg  = %5d(6172)  %0.3f'%(neg,neg/num))\n",
    "        print('\\t\\tpos  = %5d(1032)  %0.3f'%(pos,pos/num))\n",
    "        print('\\t\\tpos1 = %5d( 128)  %0.3f  %0.3f'%(pos1,pos1/num_image,pos1/pos))\n",
    "        print('\\t\\tpos2 = %5d(  43)  %0.3f  %0.3f'%(pos2,pos2/num_image,pos2/pos))\n",
    "        print('\\t\\tpos3 = %5d( 741)  %0.3f  %0.3f'%(pos3,pos3/num_image,pos3/pos))\n",
    "        print('\\t\\tpos4 = %5d( 120)  %0.3f  %0.3f'%(pos4,pos4/num_image,pos4/pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this kernel was helpful, upvote every topic that heng has posted as this is purely based on his code/ideas. Thank you again Heng!!!! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
